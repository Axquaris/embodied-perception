{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭──────────────── <span style=\"font-weight: bold\">viser</span> ────────────────╮\n",
       "│             ╷                         │\n",
       "│   HTTP      │ http://localhost:8080   │\n",
       "│   Websocket │ ws://localhost:8080     │\n",
       "│             ╵                         │\n",
       "╰───────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭──────────────── \u001b[1mviser\u001b[0m ────────────────╮\n",
       "│             ╷                         │\n",
       "│   HTTP      │ http://localhost:8080   │\n",
       "│   Websocket │ ws://localhost:8080     │\n",
       "│             ╵                         │\n",
       "╰───────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "from einops import einsum\n",
    "\n",
    "from ember.wrappers.viser import ViserServer\n",
    "from ember.torch_perf_utils import Timer\n",
    "from ember.math.quat import qvec2rotmat\n",
    "\n",
    "\n",
    "server = ViserServer()\n",
    "\n",
    "\n",
    "position_slider = server.gui.add_vector3(\n",
    "    \"Position\",\n",
    "    initial_value=(0, 0, 0),\n",
    "    min=(-5, -5, -5),\n",
    "    max=(5, 5, 5),\n",
    ")\n",
    "radius_slider = server.gui.add_slider(\n",
    "    \"Radius\",\n",
    "    min=0,\n",
    "    max=5,\n",
    "    step=0.1,\n",
    "    initial_value=1\n",
    ")\n",
    "\n",
    "resolution_slider = server.gui.add_slider(\n",
    "    \"Resolution\", min=64, max=1024, step=64, initial_value=256\n",
    ")\n",
    "fov_slider = server.gui.add_slider(\n",
    "    \"FOV\", min=30, max=170, step=10, initial_value=60\n",
    ")\n",
    "trace_iter_slider = server.gui.add_slider(\n",
    "    \"Trace Iters\", min=1, max=200, step=1, initial_value=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection opened <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total<span style=\"font-weight: bold\">)</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> persistent messages\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection opened \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m1\u001b[0m total\u001b[1m)\u001b[0m, \u001b[1;36m14\u001b[0m persistent messages\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(array([3., 3., 3.]),\n",
       " array([ 0.27984814,  0.88047624,  0.1159169 , -0.3647052 ]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bind the UI to the camera\n",
    "client, camera = server.wait_for_camera()\n",
    "\n",
    "camera_updated = True\n",
    "@camera.on_update\n",
    "def _(_):\n",
    "    global camera_updated\n",
    "    camera_updated = True\n",
    "\n",
    "@fov_slider.on_update\n",
    "def _(_) -> None:\n",
    "    camera.fov = fov_slider.value * np.pi / 180\n",
    "\n",
    "camera.position, camera.wxyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camera parameter fetchers\n",
    "def get_updated_camera_intrinsics():\n",
    "    W = resolution_slider.value\n",
    "    H = int(W / camera.aspect)\n",
    "    focal_x = W / 2 / np.tan(camera.fov/2)\n",
    "    focal_y = H / 2 / np.tan(camera.fov/2)\n",
    "\n",
    "    return W, H, focal_x, focal_y\n",
    "\n",
    "\n",
    "def get_updated_camera_extrinsics():\n",
    "    rot_c2w = torch.tensor(camera.wxyz).view(1, 4)\n",
    "    \n",
    "    return rot_c2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.jit.script\n",
    "def compute_xyo(H: int, W: int, aspect_ratio: float) -> torch.Tensor:\n",
    "    x = torch.linspace(-1, 1, W, device='cuda')\n",
    "    y = torch.linspace(-1, 1, H, device='cuda') / aspect_ratio\n",
    "    y, x = torch.meshgrid(y, x)\n",
    "    o = torch.ones_like(x)\n",
    "    xyo = torch.stack([x, y, o], dim=-1)\n",
    "    return xyo\n",
    "\n",
    "@torch.jit.script\n",
    "def sphere_sdf(\n",
    "    points: torch.Tensor,\n",
    "    sphere_pos: torch.Tensor,\n",
    "    sphere_radius: torch.Tensor,\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate the signed distance function (SDF) for a sphere.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : torch.Tensor\n",
    "        Points in space to calculate the SDF for, shape (N, 3).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Signed distance from each point to the sphere surface, shape (N,).\n",
    "    \"\"\"\n",
    "    return torch.norm(points - sphere_pos, dim=-1) - sphere_radius\n",
    "\n",
    "@torch.jit.script\n",
    "def sphere_normal(points: torch.Tensor, sphere_pos, sphere_radius) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Calculate the normal vectors for a sphere at given points.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    points : torch.Tensor\n",
    "        Points in space to calculate the normals for, shape (N, 3).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Normal vectors at each point, shape (N, 3).\n",
    "    \"\"\"\n",
    "    eps = 1e-8\n",
    "    sdf = sphere_sdf(points, sphere_pos, sphere_radius)\n",
    "    sdf_dx = sphere_sdf(\n",
    "        points + torch.tensor([eps, 0., 0.], device=\"cuda\"),\n",
    "        sphere_pos, sphere_radius\n",
    "    ) - sdf\n",
    "    sdf_dy = sphere_sdf(\n",
    "        points + torch.tensor([0., eps, 0.], device=\"cuda\"),\n",
    "        sphere_pos, sphere_radius\n",
    "    ) - sdf\n",
    "    sdf_dz = sphere_sdf(\n",
    "        points + torch.tensor([0., 0., eps], device=\"cuda\"),\n",
    "        sphere_pos, sphere_radius\n",
    "    ) - sdf\n",
    "\n",
    "    return torch.nn.functional.normalize(torch.stack([sdf_dx, sdf_dy, sdf_dz], dim=-1), dim=-1)\n",
    "\n",
    "@torch.jit.script\n",
    "def sphere_trace(\n",
    "    rays: torch.Tensor,\n",
    "    sphere_pos, sphere_radius,\n",
    "    camera_center: torch.Tensor = torch.tensor([0, 0, 0], device=\"cuda\"),\n",
    "    max_steps: int = 20,\n",
    "    min_dist: float = 0.001,\n",
    "    max_dist: float = 100.0,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Perform sphere tracing to find the intersection points of rays with a sphere.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rays : torch.Tensor\n",
    "        Rays through camera pixels in world coordinates, shape (N, 3).\n",
    "    camera_center : torch.Tensor, optional\n",
    "        The center of the camera, shape (3,). Default is [0, 0, 0]\n",
    "    max_steps : int, optional\n",
    "        Maximum number of tracing steps. Default is 20.\n",
    "    min_dist : float, optional\n",
    "        Minimum distance to consider an intersection. Default is 0.001.\n",
    "    max_dist : float, optional\n",
    "        Maximum distance to trace. Default is 100.0.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.Tensor\n",
    "        Depths of intersection points, shape (N, 1).\n",
    "    \"\"\"\n",
    "    points = torch.zeros_like(rays, device=\"cuda\")\n",
    "    depths = points[..., :1]\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        points = camera_center + depths * rays\n",
    "        dist = sphere_sdf(points, sphere_pos, sphere_radius).unsqueeze(-1)\n",
    "        depths += dist\n",
    "        if ((dist < min_dist) | (depths > max_dist)).all():\n",
    "            break\n",
    "\n",
    "    return depths, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame 0\n",
      "{'render': 'average time 0.01621147340577224s',\n",
      " 'set_bg_image': 'average time 0.012449395890071475s'}\n",
      "{'render': 'average FPS 61.68470779737646',\n",
      " 'set_bg_image': 'average FPS 80.32518275023374'}\n",
      "Frame 100\n",
      "{'render': 'average time 0.014821207651800039s',\n",
      " 'set_bg_image': 'average time 0.012092594460078647s'}\n",
      "{'render': 'average FPS 67.47088520000257',\n",
      " 'set_bg_image': 'average FPS 82.69523990912835'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     last_intrinsics \u001b[38;5;241m=\u001b[39m intrinsics\n\u001b[0;32m     15\u001b[0m rot_c2w \u001b[38;5;241m=\u001b[39m get_updated_camera_extrinsics()\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_extrinsics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mrot_c2w\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlast_extrinsics\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     17\u001b[0m     camera_center \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(camera\u001b[38;5;241m.\u001b[39mposition, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m     rot_c2w_mat \u001b[38;5;241m=\u001b[39m qvec2rotmat(camera\u001b[38;5;241m.\u001b[39mwxyz)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(viser)</span> Connection closed <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> total<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1mviser\u001b[0m\u001b[1m)\u001b[0m Connection closed \u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m, \u001b[1;36m0\u001b[0m total\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frame_idx = 0\n",
    "last_intrinsics = None\n",
    "last_extrinsics = None\n",
    "\n",
    "while True:\n",
    "    intrinsics = get_updated_camera_intrinsics()\n",
    "    if intrinsics != last_intrinsics:\n",
    "        W, H, focal_x, focal_y = intrinsics\n",
    "\n",
    "        xyo = compute_xyo(H, W, camera.aspect)\n",
    "\n",
    "        camera_updated = True\n",
    "        last_intrinsics = intrinsics\n",
    "\n",
    "    rot_c2w = get_updated_camera_extrinsics()\n",
    "    if last_extrinsics is None or (rot_c2w != last_extrinsics).any():\n",
    "        camera_center = torch.tensor(camera.position, device=\"cuda\")\n",
    "        rot_c2w_mat = qvec2rotmat(camera.wxyz).to(\"cuda\")\n",
    "\n",
    "        pixels__world_rot = einsum(\n",
    "            xyo, rot_c2w_mat, '... p, o p-> ... o'\n",
    "        )\n",
    "        pixels__world = pixels__world_rot + camera_center\n",
    "        rays = torch.nn.functional.normalize(pixels__world_rot, dim=-1)\n",
    "\n",
    "        camera_updated = True\n",
    "        last_extrinsics = rot_c2w\n",
    "\n",
    "    if camera_updated:\n",
    "        camera_updated = False\n",
    "\n",
    "        with Timer(\"render\"):\n",
    "            sphere_pos = torch.tensor(position_slider.value, device=\"cuda\")\n",
    "            sphere_radius = torch.tensor(radius_slider.value, device=\"cuda\")\n",
    "\n",
    "            depth, intersections_world = sphere_trace(\n",
    "                rays,\n",
    "                camera_center=camera_center,\n",
    "                max_steps=trace_iter_slider.value,\n",
    "                sphere_pos=sphere_pos,\n",
    "                sphere_radius=sphere_radius,\n",
    "            )\n",
    "\n",
    "            image = sphere_normals = sphere_normal(\n",
    "                intersections_world,\n",
    "                sphere_pos, sphere_radius\n",
    "            )\n",
    "            image[depth.squeeze() >= 9] = 0.  # Set background to 0 value\n",
    "\n",
    "            image -= image.min()\n",
    "            image /= image.max()\n",
    "\n",
    "        with Timer(\"set_bg_image\"):\n",
    "            client.scene.set_background_image(\n",
    "                image=image.cpu().numpy(),\n",
    "                depth=depth.cpu().numpy(),\n",
    "                # format=\"jpeg\",\n",
    "                # jpeg_quality=70,\n",
    "            )\n",
    "    \n",
    "        if frame_idx % 100 == 0:\n",
    "            print(f\"Frame {frame_idx}\")\n",
    "            Timer.show_recorder()\n",
    "\n",
    "        frame_idx += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
